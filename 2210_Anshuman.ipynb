{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.7' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/msys64/ucrt64/bin/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#first importing the libraries that are required\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "#then reading the train and test files given\n",
    "\n",
    "tst_dta = pd.read_csv(\"/kaggle/input/week4-practice-hackathon-2024/Test.csv\")\n",
    "print(f\"Test data shape: {tst_dta.shape}\")\n",
    "training_dataset = pd.read_csv(\"/kaggle/input/week4-practice-hackathon-2024/Train.csv\")\n",
    "print(f\"Training data shape: {training_dataset.shape}\")\n",
    "\n",
    "print(training_dataset.isnull().sum())\n",
    "y = training_dataset['class']\n",
    "\n",
    "X = training_dataset.drop(['class'], axis=1)\n",
    "print(training_dataset.head())\n",
    "#splitting the dataset for further processing\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "preprocessing_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "X_tr = preprocessing_pipeline.fit_transform(X_tr)\n",
    "X_val = preprocessing_pipeline.transform(X_val)\n",
    "#using a loop to find best possible learning rate\n",
    "#then hyperparameter tuning to let the model fit rightly\n",
    "learn_rate = np.linspace(0.00025, 0.00026, num=1000, endpoint=False)\n",
    "param_grid = {\n",
    "    'colsample_bytree': [0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8,0.84,0.86,0.83,0.87, 0.85, 0.9, 0.95, 1.0],\n",
    "    'learning_rate': learn_rate,\n",
    "    'n_estimators': [90, 95, 100,103,107, 105, 110, 115, 150, 200, 250],\n",
    "    'subsample': [0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75,0.74,0.76,0.73,0.78, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "}\n",
    "\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "#increased no of iterations and also cross validations as usual\n",
    "random_search = RandomizedSearchCV(estimator=xgb_classifier, param_distributions=param_grid, \n",
    "                                   n_iter=15, cv=3, scoring='f1', random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_tr, y_tr)\n",
    "best_xgb_classifier.fit(X_tr, y_tr)\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "best_xgb_classifier = random_search.best_estimator_\n",
    "y_prd = best_xgb_classifier.predict(X_val)\n",
    "\n",
    "f1 = f1_score(y_val, y_prd)\n",
    "\n",
    "\n",
    "Index = tst_dta['Index']\n",
    "tst_dta.drop(['Index'], axis=1, inplace=True)\n",
    "tst_dta = preprocessing_pipeline.transform(tst_dta)\n",
    "#checking the evaluation metric that is the F1 score\n",
    "print(f\"F1 score after tuning: {f1}\")\n",
    "#defining first 2 columns in new csv file to be printed out soon!!\n",
    "y_tst = best_xgb_classifier.predict(tst_dta)\n",
    "submission = pd.DataFrame({\n",
    "    'Index': Index,\n",
    "    'class': y_tst\n",
    "})\n",
    "#finally we have to print out the final file for submission\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Final file has been created successfully!!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
